---
title: "preparation of suppl tables"
author: "BS"
date: "2023-01-17"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## load libraries
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(Biostrings)
library(biomartr)
library(stringr)
library(Peptides)
library(seqinr)
library(protti)
```


## read uniprot fasta file which was used during DIA-NN search
can be downloaded from ProteomeExchange repository (PXD038014)
```{r}
# read fasta file as `Biostrings AAStringSet` object
fasta_file <- read_proteome("uniprot-proteome_UP000008227_20012022_49792_1438.fasta", obj.type = "Biostrings")
```



## convert fasta file to dataframe
```{r}
fasta_df <- as.data.frame(fasta_file) %>% 
            tibble::rownames_to_column("name") %>% 
            dplyr::rename(sequence = x)
rm(fasta_file)
```


## read proteingroups and peptides file (output of pepquantify)
```{r}
proteingroups_data  <- read.delim("../DIA quant with MS-EmpiRe/proteingroups.txt")
peptides_data       <- read.delim("../DIA quant with MS-EmpiRe/peptides.txt")
```


## tidy the peptide file
```{r}
# prepare for the supplementary data
peptides_data_suppl <- peptides_data %>% 
  mutate("Mass (theoretical)" = Peptides::mw(Stripped.Sequence, monoisotopic = T)) %>% 
  select(Stripped.Sequence, Genes, Protein.Group, First.Protein.Description, Modification, Charge, 
         Q.value, "Mass (theoretical)", starts_with("Precursor")) %>% 
  dplyr::rename("Stripped sequence" = Stripped.Sequence,
                "Protein group"     = Protein.Group,
                "First protein description"           = First.Protein.Description,
                Modification        = Modification) %>% 
  rename_all(~str_replace(., "Precursor.Quantity_", "Intensity.")) %>% 
  rename_all(~str_replace(., "Precursor.Normalised_", "Normalized.intensity."))
```


## calculate sequence coverage
```{r}
# list of identified proteins (only first accession)
seq_cov_data <- peptides_data %>%
  select(Stripped.Sequence, Protein.Group) %>% 
  mutate(first_protein = str_remove(Protein.Group, ";.*")) 

# prepare fasta file to match proteins and get the sequence 
# protein name in uniprot is between two vertical lines, following extracts proteins in a new column from each entry
fasta_df <- fasta_df %>%
   mutate(protein = str_extract_all(name,"(?<=\\|).+(?=\\|)")) %>% 
   mutate(protein = as.character(protein))

# add full protein sequence to each identified protein 
seq_cov_data <- seq_cov_data %>% 
  left_join(fasta_df %>% select(sequence, protein), by = c("first_protein" = "protein")) %>% 
  select(Stripped.Sequence, sequence)

# calculate sequence coverage using protti package
seq_cov <- calculate_sequence_coverage(
  seq_cov_data,
  protein_sequence = sequence,
  peptides = Stripped.Sequence)

# add protein groups
seq_cov <- seq_cov %>% 
  left_join(peptides_data %>% select(Stripped.Sequence, Protein.Group, Genes)) %>% 
  select(coverage, Genes) %>% 
  group_by(Genes) %>%
  summarise(coverage   = max(coverage))
```


## add extra columns to proteingroup file (arrange descending intensity)
```{r}
# add sequence coverage to protein groups
proteingroups_suppl <- proteingroups_data %>% 
  left_join(seq_cov) %>% 
  select(Genes, second_ids, First.Protein.Description, n_pep, coverage, pg_Q_Val, contains("MIDY"), contains("WT")) %>% 
  rowwise() %>% 
  mutate(total = sum(na.rm = T, c_across(contains("LFQ")))) %>% 
  arrange(desc(total)) %>% 
  select(-total) %>% 
  dplyr::rename("Protein group"       = second_ids,
         "First protein name"         = First.Protein.Description,
         "Unique peptides"            = n_pep,
         "Q-value"                    = pg_Q_Val,
         "Unique sequence coverage %" = coverage)
```



## save supplementary tables
```{r}
# supplementary table 1 (peptide)
Suppl_table_1 <- peptides_data_suppl %>% 
  write.table("Suppl_table_1.txt", sep = "\t", row.names = F, quote = F)

# supplementary table 2 (proteins)
Suppl_table_2 <- proteingroups_suppl %>% 
  write.table("Suppl_table_2.txt", sep = "\t", row.names = F, quote = F)

# supplementary table 3 (msempire)
Suppl_table_3 <- read.delim("../DIA quant with MS-EmpiRe/MIDY_vs_WT/msempire_results_tidy.txt") %>% 
  select(-n_imputed) %>% 
  left_join(proteingroups_suppl %>% select(1:3), by = c("accession" = "Genes")) %>%
  select(accession, "Protein group", "First protein name", n_pep_total, l2fc, p_value, adj_p_value) %>% 
  filter(adj_p_value <= 0.05) %>% 
  arrange(desc(l2fc)) %>% 
  mutate(l2fc = round(l2fc,2)) %>% 
  dplyr::rename(Genes = accession,
                "Peptides (quantified)" = n_pep_total,
                "log2 fold change (MIDY/WT)" = l2fc,
                "P-value" = p_value,
                "P-value adjusted (BH)" = adj_p_value) %>% 
  write.table("Suppl_table_3.txt", sep = "\t", row.names = F, quote = F)

# supplementary table 4 (STRING results)
Suppl_table_4 <- read.delim("../proteomics bioinformatics/enrichment.Process_raw.tsv", check.names = F) %>% 
  select(-`matching proteins in your input (IDs)`) 
names(Suppl_table_4) <- str_to_sentence(names(Suppl_table_4))  
write.table(Suppl_table_4, "Suppl_table_4.txt", sep = "\t", row.names = F, quote = F)

# supplementary table 5 (lipidomics raw)
Suppl_table_5 <- read.delim("../lipidomics bioinformatics/lipidomics_raw.txt") %>% 
  write.table("Suppl_table_5.txt", sep = "\t", row.names = F, quote = F)

# supplementary table 6 (lipidomics raw)
Suppl_table_6 <- read.delim("../correlation heatmap and network lipid/correlations.txt", check.names = F) %>% 
  mutate_if(is.numeric, round,2) %>% 
  write.table("Suppl_table_6.txt", sep = "\t", row.names = F, quote = F)

# supplementary table 7 (lipidomics statistics)
Suppl_table_7 <- read.delim("../lipidomics bioinformatics/lipidomics_stat.txt") %>% 
  select(Compound, l2fc, t.test_p.val, VIP) %>% 
  mutate(l2fc = round(l2fc,2)) %>% 
  dplyr::rename("log2 fold change (MIDY/WT)" = l2fc,
                "P-value" = t.test_p.val,
                "Variance importance in projection (VIP-score)" = VIP) %>% 
  write.table("Suppl_table_7.txt", sep = "\t", row.names = F, quote = F)
```
